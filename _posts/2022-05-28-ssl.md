---
layout: post
title:  "How robust are pre-trained models to distribution shift?"
date:   2022-05-15 00:00:00 +00:00
image: /images/ssl-robust.png
categories: research
author:  <a href="https://yugeten.github.io/"> Yuge Shi</a>, <a href="https://mds.inf.ethz.ch/team/detail/imant-daunhawer"> Imant Daunhawer</a>, Julia E. Vogt, <strong> Amartya Sanyal </strong>, <a href="https://www.robots.ox.ac.uk/~phst/">Philip H.S. Torr</a> 
subtitle: "SSL models are robust to distribution shift"
accepted: yes
venue: <a href="https://sites.google.com/view/scis-workshop/home"> Spurious Correlation, Invariance, and Instability</a>, <a href="https://pretraining.github.io/"> Pre-training- Perspectives, Pitfalls, and Paths Forward </a>
spotlight: Workshop Paper
important: new
paper: https://arxiv.org/pdf/2206.08871.pdf
---
Our paper titled <a href="https://arxiv.org/abs/2206.08871">
How robust are pre-trained models to distribution shift? </a> on the
robustness of unsupervised and self-supervised models to distribution
shift and simplicity bias is now on arxiv.
