---
layout: post
title:  "A law of adversarial risk, interpolation, and label noise"
date:   2022-07-08 00:00:00 +00:00
image: /images/law-robust.png
categories: research
author:  <a href="https://danielpaleka.com/"> Daniel Paleka</a>, <strong> Amartya Sanyal </strong>
subtitle: "Interpolating label noise makes models vulnerable to adversarial attacks"
accepted: yes
venue: Workshop on <a href="https://responsibledecisionmaking.github.io/submit/"> Responsible decision making in dynamic environments</a>, ICML 2022.
spotlight: Workshop Paper
important: new
paper: https://arxiv.org/pdf/2207.03933.pdf
---
Our paper titled <a href="https://arxiv.org/abs/2207.03933"> A law of
adversarial risk, interpolation, and label noise  </a> provides a
lower bound on adversrial vulernability due to interpolating label
noise. We show how to use distributional properties and inductive
biases of models to further strenghten this.
